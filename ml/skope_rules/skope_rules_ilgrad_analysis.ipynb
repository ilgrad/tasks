{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skope_rules\n",
    "\n",
    "https://skope-rules.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/scikit-learn-contrib/skope-rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections.abc import Iterable\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numbers\n",
    "from warnings import warn\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import check_classification_targets\n",
    "from sklearn.utils import indices_to_mask\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor, GradientBoostingClassifier,\\\n",
    "    RandomForestClassifier\n",
    "from sklearn.tree import _tree\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, confusion_matrix\n",
    "from sklearn.datasets import load_boston, load_iris\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import cm\n",
    "\n",
    "INTEGER_TYPES = (numbers.Integral, np.integer)\n",
    "BASE_FEATURE_NAME = \"__C__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция замены общих имен функций реальными именами функций\n",
    "def replace_feature_name(rule, replace_dict):\n",
    "    def replace(match):\n",
    "        return replace_dict[match.group(0)]\n",
    "\n",
    "    rule = re.sub('|'.join(r'\\b%s\\b' % re.escape(s) for s in replace_dict),\n",
    "                  replace, rule)\n",
    "    return rule\n",
    "\n",
    "# класс Правил\n",
    "class Rule:\n",
    "    \"\"\" Объект моделирует логическое правило и добавляет методы факторизации.\n",
    "    Это используется для упрощения правил и их дедупликации.\n",
    "\n",
    "    Параметры\n",
    "    ----------\n",
    "    rule : str\n",
    "        Логическое правило, которое можно интерпретировать с помощью запроса pandas.\n",
    "    args : object, optional\n",
    "        Аргументы связанные с правилом, они не используются для факторизации,\n",
    "        но принимают часть вывода когда правило преобразовывается в массив.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rule, args=None):\n",
    "        self.rule = rule\n",
    "        self.args = args\n",
    "        self.terms = [t.split(' ') for t in self.rule.split(' and ')]\n",
    "        self.agg_dict = {}\n",
    "        self.factorize()\n",
    "        self.rule = str(self)\n",
    "\n",
    "    # функция проверки одинаковых словарей\n",
    "    def __eq__(self, other):\n",
    "        return self.agg_dict == other.agg_dict\n",
    "\n",
    "    # функция получения hash объектов\n",
    "    def __hash__(self):\n",
    "        # FIXME : Easier method ?\n",
    "        return hash(tuple(sorted(((i, j) for i, j in self.agg_dict.items()))))\n",
    "\n",
    "    # функция факторизации\n",
    "    def factorize(self):\n",
    "        for feature, symbol, value in self.terms:\n",
    "            if (feature, symbol) not in self.agg_dict:\n",
    "                if symbol != '==':\n",
    "                    self.agg_dict[(feature, symbol)] = str(float(value))\n",
    "                else:\n",
    "                    self.agg_dict[(feature, symbol)] = value\n",
    "            else:\n",
    "                if symbol[0] == '<':\n",
    "                    self.agg_dict[(feature, symbol)] = str(min(\n",
    "                                float(self.agg_dict[(feature, symbol)]),\n",
    "                                float(value)))\n",
    "                elif symbol[0] == '>':\n",
    "                    self.agg_dict[(feature, symbol)] = str(max(\n",
    "                                float(self.agg_dict[(feature, symbol)]),\n",
    "                                float(value)))\n",
    "                else:  # Handle the c0 == c0 case\n",
    "                    self.agg_dict[(feature, symbol)] = value\n",
    "\n",
    "    # функция итераторов\n",
    "    def __iter__(self):\n",
    "        yield str(self)\n",
    "        yield self.args\n",
    "\n",
    "    # функция которая возвращает строковое представление правила\n",
    "    def __repr__(self):\n",
    "        return ' and '.join([' '.join(\n",
    "                [feature, symbol, str(self.agg_dict[(feature, symbol)])])\n",
    "                for feature, symbol in sorted(self.agg_dict.keys())\n",
    "                ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkopeRules(BaseEstimator):\n",
    "    \"\"\"Легко интерпретируемый классификатор, оптимизирующий простые логические правила.\n",
    "\n",
    "    Параметры\n",
    "    ----------\n",
    "\n",
    "    feature_names : list of str, optional\n",
    "        Список имен признаков, используемых для возвращения правил в строковом формате\n",
    "\n",
    "    precision_min : float, optional (default=0.5)\n",
    "        Минимальная точность(precision) с котороый правило будет выбрано.\n",
    "\n",
    "    recall_min : float, optional (default=0.01)\n",
    "        Минимальная полнота(recall)  с которой правило будет выбрано.\n",
    "\n",
    "    n_estimators : int, optional (default=10)\n",
    "        Количество деревьев в лесу(правил) которое будет использовано для предсказания.\n",
    "        Еще больше строится перед отбором. Все доступно в аттрибуте estimators_.\n",
    "\n",
    "    max_samples : int or float, optional (default=.8)\n",
    "        Количество данных которое нужно взять из X для обучения каждого дерева решений,\n",
    "        из которых правила генерируются и выбираются.\n",
    "            - если int, тогда берется `max_samples` данных.\n",
    "            - если float, тогда берется `max_samples * X.shape[0]` данных.\n",
    "        Если max_samples больше чем размер предоставленных данных,\n",
    "        все данные будут использоваться для всех деревьев.\n",
    "\n",
    "    max_samples_features : int or float, optional (default=1.0)\n",
    "        Количество признаков которое нужно извлечь из X для обучения каждого дерева решений,\n",
    "        из которого создаются и выбираются правила.\n",
    "            - если int, тогда выбирается `max_features` признаков.\n",
    "            - если float, тогда выбирается `max_features * X.shape[1]` признаков.\n",
    "\n",
    "    bootstrap : boolean, optional (default=False)\n",
    "        Отбор наблюдений с возвращением.\n",
    "\n",
    "    bootstrap_features : boolean, optional (default=False)\n",
    "        Отбор признаков с возвращением.\n",
    "\n",
    "    max_depth : integer or List or None, optional (default=3)\n",
    "        Максимальная глубина деревьев решений. Если None, тогда узлы\n",
    "        расширяются до тех пор, пока все листья не станут чистыми или пока\n",
    "        все листья не будут содержать менее min_samples_split данных.\n",
    "        Если итерация пройдена, вы обучите n_estimators для каждой глубины дерева.\n",
    "        Это позволяет создавать и сравнивать правила разной длины.\n",
    "\n",
    "    max_depth_duplication : integer, optional (default=None)\n",
    "        Максимальная глубина дерева решений для дедупликации правил,\n",
    "        если None то дедупликации не происходит.\n",
    "\n",
    "    max_features : int, float, string or None, optional (default=\"auto\")\n",
    "        Количество признаков, рассматриваемых(каждым деревом решений)\n",
    "        при поиске для лучшего разделения:\n",
    "        - если int, тогда рассматриваем `max_features` признаков при каждом разделении.\n",
    "        - если float, тогда `max_features` это процент и `int(max_features * n_features)` признаков\n",
    "            рассматриваются при каждом разделении.\n",
    "        - если \"auto\", тогда `max_features=sqrt(n_features)`.\n",
    "        - если \"sqrt\", тогда `max_features=sqrt(n_features)` (тоже самое что и \"auto\").\n",
    "        - если \"log2\", тогда `max_features=log2(n_features)`.\n",
    "        - если None, тогда `max_features=n_features`.\n",
    "\n",
    "        Примечание: поиск разбиения не прекращается до тех пор, пока не будет найден\n",
    "        хотя бы один допустимый раздел образцов узлов, даже если для этого требуется\n",
    "        эффективно проверить более чем ``max_features`` признаков.\n",
    "\n",
    "    min_samples_split : int, float, optional (default=2)\n",
    "        Минимальное количество данных необходимых для разделения внутреннего узла для каждого дерева решений.\n",
    "        - если int, тогда считается `min_samples_split` как минимальное число.\n",
    "        - если float, тогда `min_samples_split` это процент и\n",
    "            `ceil(min_samples_split * n_samples)` минимальное количество данных для каждого разделения.\n",
    "    n_jobs : integer, optional (default=1)\n",
    "        Количество задач, которые будут выполняться параллельно как для `fit` и `predict`.\n",
    "        Если -1, тогда число задач равно числу ядер процессора.\n",
    "\n",
    "    random_state : int, RandomState instance or None, optional\n",
    "        - если int, random_state это начальное число, используемое генератором случайных чисел.\n",
    "        - если RandomState задается генератор случайных чисел.\n",
    "        - если None, используется генератор случайных чисел из RandomState `np.random`.\n",
    "\n",
    "    verbose : int, optional (default=0)\n",
    "        Управляет детализацией процесса построения дерева.\n",
    "\n",
    "    Аттрибуты\n",
    "    ----------\n",
    "    rules_ : dict of tuples (rule, precision, recall, nb).\n",
    "        Коллекция `n_estimators`  правил используемых в методе ``predict``.\n",
    "        Правила генерируются по подобранным sub-estimators(деревам решений).\n",
    "        Каждое правило удовлетворяет условиям recall_min и precision_min.\n",
    "        Выбор выполняется с соблюдением точности OOB(Out-of-bag).\n",
    "\n",
    "    estimators_ : list of DecisionTreeClassifier\n",
    "        Набор подобранных суб-оценок, используемых для создания правил-кандидатов.\n",
    "\n",
    "    estimators_samples_ : list of arrays\n",
    "        Подмножество отобранных данных (то есть данных из бэггинга) для каждого базового дерева.\n",
    "\n",
    "    estimators_features_ : list of arrays\n",
    "        Подмножество выбранных признаков для каждого базового дерева.\n",
    "\n",
    "    max_samples_ : integer\n",
    "        Актуальный размер данных.\n",
    "\n",
    "    n_features_ : integer\n",
    "        Количество признаков при выполнении  ``fit``.\n",
    "\n",
    "    classes_ : array, shape (n_classes,)\n",
    "        метки классов\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 feature_names=None,\n",
    "                 precision_min=0.5,\n",
    "                 recall_min=0.01,\n",
    "                 n_estimators=10,\n",
    "                 max_samples=.8,\n",
    "                 max_samples_features=1.,\n",
    "                 bootstrap=False,\n",
    "                 bootstrap_features=False,\n",
    "                 max_depth=3,\n",
    "                 max_depth_duplication=None,\n",
    "                 max_features=1.,\n",
    "                 min_samples_split=2,\n",
    "                 n_jobs=1,\n",
    "                 random_state=None,\n",
    "                 verbose=0):\n",
    "        # минимальная точность\n",
    "        self.precision_min = precision_min\n",
    "        # минимальная полнота\n",
    "        self.recall_min = recall_min\n",
    "        # названия признаков\n",
    "        self.feature_names = feature_names\n",
    "        # количество деревьев решений\n",
    "        self.n_estimators = n_estimators\n",
    "        # актуальный размер данных\n",
    "        self.max_samples = max_samples\n",
    "        # максимальное количество признаков\n",
    "        self.max_samples_features = max_samples_features\n",
    "        # флаг бутстрепа\n",
    "        self.bootstrap = bootstrap\n",
    "        # флаг бутстрепа признаков\n",
    "        self.bootstrap_features = bootstrap_features\n",
    "        # максимальная глубина\n",
    "        self.max_depth = max_depth\n",
    "        # максимальная глубина дерева решений для дедупликации правил\n",
    "        self.max_depth_duplication = max_depth_duplication\n",
    "        # максимальное количество признаков для лучшего разделения\n",
    "        self.max_features = max_features\n",
    "        # минимальное количество данных для разделения внутреннего узла дерева\n",
    "        self.min_samples_split = min_samples_split\n",
    "        # количество потоков\n",
    "        self.n_jobs = n_jobs\n",
    "        # фиксация генератора случайных чисел\n",
    "        self.random_state = random_state\n",
    "        # режим детализации вывода\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        \"\"\"Обучение модели в соответствии с заданными тренировочными данными.\n",
    "\n",
    "        Параметры\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Обучающий вектор, где n_samples количество данных и\n",
    "            n_features количество признаков.\n",
    "\n",
    "        y : array-like, shape (n_samples,)\n",
    "            Целевой вектор относительно X. Должен быть размечен как 0 - для нормальных данных,\n",
    "            1 - для аномалий.\n",
    "\n",
    "        sample_weight : array-like, shape (n_samples,) optional\n",
    "            Массив весов которые назначаются отдельным данным,\n",
    "            обычно сумма в случае транзакционных данных. Используется для\n",
    "            построения регрессионных деревьев для получения дополнительных правил для тестирования.\n",
    "            Если не указан, то каждому образцу дается единичный вес.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "\n",
    "        # проверка тренировочных данных на соответствие стандартам обучения scikit-learn\n",
    "        X, y = check_X_y(X, y)\n",
    "        # проверка целевого вектора что он не относится к регрессионому типу\n",
    "        check_classification_targets(y)\n",
    "        # количество признаков\n",
    "        self.n_features_ = X.shape[1]\n",
    "        # названия классов(меток)\n",
    "        self.classes_ = np.unique(y)\n",
    "        # общее число классов(меток)\n",
    "        n_classes = len(self.classes_)\n",
    "\n",
    "        # проверка, нужно 2 или более классов\n",
    "        if n_classes < 2:\n",
    "            raise ValueError(\"Этот метод требует выборки как минимум двух классов в данных,\"\n",
    "                             \" но данные содержат только один класс  %r\" % self.classes_[0])\n",
    "\n",
    "        # ошибка если максимальная глубина дерева решений для дедупликации правил не задана как целое число int\n",
    "        # и не является None\n",
    "        if not isinstance(self.max_depth_duplication, int) \\\n",
    "                and self.max_depth_duplication is not None:\n",
    "            raise ValueError(\"max_depth_duplication должно быть целым числом\")\n",
    "\n",
    "        # проверка на корректное задание меток класса\n",
    "        if not set(self.classes_) == set([0, 1]):\n",
    "            warn(\"Найденны метки %s. Этот метод предполагает, что целевой класс\"\n",
    "                 \" должен быть помечен как 1, а обычные данные - как 0. Любая метка, отличная от 0,\"\n",
    "                 \"будет считаться принадлежащей целевому классу.\"% set(self.classes_))\n",
    "            y = (y > 0)\n",
    "\n",
    "        # убедитесь что число данных находится в диапазоне [1, n_samples]\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        # если актуальный размер данных задан как строка\n",
    "        if isinstance(self.max_samples, str):\n",
    "            raise ValueError('max_samples (%s) не поддерживается.'\n",
    "                             'Допустимые варианты: \"auto\", int или'\n",
    "                             'float' % self.max_samples)\n",
    "        # если max_samples соответствует типу (<class 'numbers.Integral'>, <class 'numpy.integer'>)\n",
    "        elif isinstance(self.max_samples, INTEGER_TYPES):\n",
    "            if self.max_samples > n_samples:\n",
    "                warn(\"max_samples (%s) больше чем \"\n",
    "                     \"общее количество данных (%s). max_samples \"\n",
    "                     \"будет установлено значение n_samples для оценки.\"\n",
    "                     % (self.max_samples, n_samples))\n",
    "                max_samples = n_samples\n",
    "            else:\n",
    "                max_samples = self.max_samples\n",
    "        else:  # float\n",
    "            if not (0. < self.max_samples <= 1.):\n",
    "                raise ValueError(\"max_samples должен быть в (0, 1], получено %r\"\n",
    "                                 % self.max_samples)\n",
    "            max_samples = int(self.max_samples * X.shape[0])\n",
    "        # максимальное число входных данных\n",
    "        self.max_samples_ = max_samples\n",
    "\n",
    "        # словарь правил\n",
    "        self.rules_ = {}\n",
    "        # спикок оценщиков\n",
    "        self.estimators_ = []\n",
    "        # список данных оценщиков\n",
    "        self.estimators_samples_ = []\n",
    "        # спикок признаков оценщиков\n",
    "        self.estimators_features_ = []\n",
    "\n",
    "        #  имена стоблцов по умолчанию :\n",
    "        feature_names_ = [BASE_FEATURE_NAME + x for x in\n",
    "                          np.arange(X.shape[1]).astype(str)]\n",
    "        if self.feature_names is not None:\n",
    "            self.feature_dict_ = {BASE_FEATURE_NAME + str(i): feat\n",
    "                                  for i, feat in enumerate(self.feature_names)}\n",
    "        else:\n",
    "            self.feature_dict_ = {BASE_FEATURE_NAME + str(i): feat\n",
    "                                  for i, feat in enumerate(feature_names_)}\n",
    "        self.feature_names_ = feature_names_\n",
    "\n",
    "        # список BaggingClassifier\n",
    "        clfs = []\n",
    "        # спикок BaggingRegressor\n",
    "        regs = []\n",
    "\n",
    "        # максимальная глубина\n",
    "        self._max_depths = self.max_depth \\\n",
    "            if isinstance(self.max_depth, Iterable) else [self.max_depth]\n",
    "\n",
    "        # цикл до максимально заданной глубины\n",
    "        for max_depth in self._max_depths:\n",
    "            # построение ансамбля деревьев решений в помощью BaggingClassifier\n",
    "            bagging_clf = BaggingClassifier(\n",
    "                # берем классификатор дерева решений.\n",
    "                base_estimator=DecisionTreeClassifier(\n",
    "                    # максимальная глубина\n",
    "                    max_depth=max_depth,\n",
    "                    # максимальное количество признаков\n",
    "                    max_features=self.max_features,\n",
    "                    # минимальное количество данных для разделения внутреннего узла дерева\n",
    "                    min_samples_split=self.min_samples_split),\n",
    "                # количество деревьев решений\n",
    "                n_estimators=self.n_estimators,\n",
    "                # маскимальное количество данных\n",
    "                max_samples=self.max_samples_,\n",
    "                # максимальное количество признаков\n",
    "                max_features=self.max_samples_features,\n",
    "                # флаг бутстрепа\n",
    "                bootstrap=self.bootstrap,\n",
    "                # флаг бутстрепа признаков\n",
    "                bootstrap_features=self.bootstrap_features,\n",
    "                # oob_score=... XXX may be added\n",
    "                # if selection on tree perf needed.\n",
    "                # warm_start=... XXX may be added to increase computation perf.\n",
    "                n_jobs=self.n_jobs,\n",
    "                random_state=self.random_state,\n",
    "                verbose=self.verbose)\n",
    "            # построение ансамбля деревьев решений с помощью BaggingRegressor\n",
    "            bagging_reg = BaggingRegressor(\n",
    "                # берем регрессор дерева решений.\n",
    "                base_estimator=DecisionTreeRegressor(\n",
    "                    max_depth=max_depth,\n",
    "                    max_features=self.max_features,\n",
    "                    min_samples_split=self.min_samples_split),\n",
    "                n_estimators=self.n_estimators,\n",
    "                max_samples=self.max_samples_,\n",
    "                max_features=self.max_samples_features,\n",
    "                bootstrap=self.bootstrap,\n",
    "                bootstrap_features=self.bootstrap_features,\n",
    "                # oob_score=... XXX may be added\n",
    "                # if selection on tree perf needed.\n",
    "                # warm_start=... XXX may be added to increase computation perf.\n",
    "                n_jobs=self.n_jobs,\n",
    "                random_state=self.random_state,\n",
    "                verbose=self.verbose)\n",
    "            # добавляем в списки\n",
    "            clfs.append(bagging_clf)\n",
    "            regs.append(bagging_reg)\n",
    "\n",
    "        # настройки по умолчанию целевого значения регрессии:\n",
    "        # если веса заданы\n",
    "        if sample_weight is not None:\n",
    "            # проверка весов\n",
    "            sample_weight = check_array(sample_weight, ensure_2d=False)\n",
    "            weights = sample_weight - sample_weight.min()\n",
    "            # загрязнение данных\n",
    "            contamination = float(sum(y)) / len(y)\n",
    "            y_reg = (\n",
    "                    pow(weights, 0.5) * 0.5 / contamination * (y > 0) -\n",
    "                    pow((weights).mean(), 0.5) * (y == 0))\n",
    "            # сигмоида\n",
    "            y_reg = 1. / (1 + np.exp(-y_reg))\n",
    "        else:\n",
    "            # такая же как и другой бэггинг классификации\n",
    "            y_reg = y\n",
    "        # проходимся циклом по списку классификаторов, обучаем ансамбли и сохраняем данные\n",
    "        for clf in clfs:\n",
    "            clf.fit(X, y)\n",
    "            self.estimators_ += clf.estimators_\n",
    "            self.estimators_samples_ += clf.estimators_samples_\n",
    "            self.estimators_features_ += clf.estimators_features_\n",
    "\n",
    "        # проходимся циклом по списку регрессии, обучаем ансамбли и сохраняем данные\n",
    "        for reg in regs:\n",
    "            reg.fit(X, y_reg)\n",
    "            self.estimators_ += reg.estimators_\n",
    "            self.estimators_samples_ += reg.estimators_samples_\n",
    "            self.estimators_features_ += reg.estimators_features_\n",
    "\n",
    "        # список правил\n",
    "        rules_ = []\n",
    "        for estimator, samples, features in zip(self.estimators_,\n",
    "                                                self.estimators_samples_,\n",
    "                                                self.estimators_features_):\n",
    "            # Создание маски для  OOB выборок\n",
    "            mask = ~indices_to_mask(samples, n_samples)\n",
    "            #\n",
    "            if sum(mask) == 0:\n",
    "                warn(\"Оценка OOB невозможна: doing it in-bag.\"\n",
    "                     \" Оценка эффективности может быть неправильной\"\n",
    "                     \" (переобучение) и выбранные правила скорее всего не будут работать!\"\n",
    "                     \" Пожалуйста используйте max_samples < 1.\")\n",
    "                mask = samples\n",
    "            # правила из дерева\n",
    "            rules_from_tree = self._tree_to_rules(\n",
    "                estimator, np.array(self.feature_names_)[features])\n",
    "\n",
    "            # XXX todo: idem without dataframe\n",
    "            X_oob = pd.DataFrame((X[mask, :])[:, features],\n",
    "                                     columns=np.array(\n",
    "                                         self.feature_names_)[features])\n",
    "\n",
    "            if X_oob.shape[1] > 1:  # otherwise pandas bug (cf. issue #16363)\n",
    "                y_oob = y[mask]\n",
    "                y_oob = np.array((y_oob != 0))\n",
    "\n",
    "                # Add OOB performances to rules:\n",
    "                rules_from_tree = [(r, self._eval_rule_perf(r, X_oob, y_oob))\n",
    "                                   for r in set(rules_from_tree)]\n",
    "                rules_ += rules_from_tree\n",
    "\n",
    "        # Факторизация правил до семантической фильтрации дерева\n",
    "        rules_ = [\n",
    "            tuple(rule)\n",
    "            for rule in\n",
    "            [Rule(r, args=args) for r, args in rules_]]\n",
    "\n",
    "        # оставить только правила проверяющие  precision_min и recall_min:\n",
    "        for rule, score in rules_:\n",
    "            if score[0] >= self.precision_min and score[1] >= self.recall_min:\n",
    "                if rule in self.rules_:\n",
    "                    # обновить счет до нового среднего\n",
    "                    c = self.rules_[rule][2] + 1\n",
    "                    b = self.rules_[rule][1] + 1. / c * (\n",
    "                            score[1] - self.rules_[rule][1])\n",
    "                    a = self.rules_[rule][0] + 1. / c * (\n",
    "                            score[0] - self.rules_[rule][0])\n",
    "\n",
    "                    self.rules_[rule] = (a, b, c)\n",
    "                else:\n",
    "                    self.rules_[rule] = (score[0], score[1], 1)\n",
    "\n",
    "        self.rules_ = sorted(self.rules_.items(),\n",
    "                             key=lambda x: (x[1][0], x[1][1]), reverse=True)\n",
    "\n",
    "        # Дедуплицирование правила используя семантическое дерево\n",
    "        if self.max_depth_duplication is not None:\n",
    "            self.rules_ = self.deduplicate(self.rules_)\n",
    "\n",
    "        self.rules_ = sorted(self.rules_, key=lambda x: - self.f1_score(x))\n",
    "        self.rules_without_feature_names_ = self.rules_\n",
    "\n",
    "        # Замена общих имен функций реальными именами функций\n",
    "        self.rules_ = [(replace_feature_name(rule, self.feature_dict_), perf)\n",
    "                       for rule, perf in self.rules_]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Предсказание является ли конкретная выборка выбросом или нет.\n",
    "\n",
    "        Параметры\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Входные данные. Внутри они будут преобразованы в тип\n",
    "            ``dtype=np.float32``\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        is_outlier : array, shape (n_samples,)\n",
    "            Для каждого наблюдения сообщает так или иначе (1 или 0)  следует или нет\n",
    "            данные рассматривать как выброс в соответствии с выбранными правилами.\n",
    "        \"\"\"\n",
    "\n",
    "        return np.array((self.decision_function(X) > 0), dtype=int)\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        \"\"\"Средняя оценка аномальности X базовых классификаторов (правил).\n",
    "\n",
    "        Оценка аномалии входной выборки вычисляется\n",
    "        как взвешенная сумма выходных двоичных правил,\n",
    "        причем вес является соответствующей точностью каждого правила.\n",
    "\n",
    "        Параметры\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Тренировочный набор данных.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        scores : array, shape (n_samples,)\n",
    "            Оценка аномалий входных данных.\n",
    "            Чем выше, тем ненормальнее. Положительные оценки представляют собой выбросы,\n",
    "            нулевые оценки представляют не выброс(inliers).\n",
    "        \"\"\"\n",
    "        # Проверяем если был вызван метод fit\n",
    "        check_is_fitted(self, ['rules_', 'estimators_', 'estimators_samples_',\n",
    "                               'max_samples_'])\n",
    "\n",
    "        # проверка входных данных\n",
    "        X = check_array(X)\n",
    "\n",
    "        if X.shape[1] != self.n_features_:\n",
    "            raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n",
    "                             \"the number of features at training time.\"\n",
    "                             \" Please reshape your data.\"\n",
    "                             % (X.shape[1], self.n_features_))\n",
    "\n",
    "        df = pd.DataFrame(X, columns=self.feature_names_)\n",
    "        selected_rules = self.rules_without_feature_names_\n",
    "\n",
    "        scores = np.zeros(X.shape[0])\n",
    "        for (r, w) in selected_rules:\n",
    "            scores[list(df.query(r).index)] += w[0]\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def rules_vote(self, X):\n",
    "        \"\"\"Оценка, представляющая голосование базовых классификаторов (правил).\n",
    "\n",
    "        Оценка входной выборки вычисляется\n",
    "        как сумма выходных двоичных правил: оценка k означает, что k правил проголосовали положительно.\n",
    "\n",
    "        Параметры\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Тренировочный набор данных\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        scores : array, shape (n_samples,)\n",
    "            Оценка исходных образцов.\n",
    "            Чем выше, тем ненормальнее. Положительные оценки представляют собой выбросы,\n",
    "            нулевые оценки представляют собой вставки(inliers).\n",
    "        \"\"\"\n",
    "        # Проверяем если был вызван метод fit\n",
    "        check_is_fitted(self, ['rules_', 'estimators_', 'estimators_samples_',\n",
    "                               'max_samples_'])\n",
    "\n",
    "        # Проверка входных данных\n",
    "        X = check_array(X)\n",
    "\n",
    "        if X.shape[1] != self.n_features_:\n",
    "            raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n",
    "                             \"the number of features at training time.\"\n",
    "                             \" Please reshape your data.\"\n",
    "                             % (X.shape[1], self.n_features_))\n",
    "\n",
    "        df = pd.DataFrame(X, columns=self.feature_names_)\n",
    "        selected_rules = self.rules_\n",
    "\n",
    "        scores = np.zeros(X.shape[0])\n",
    "        for (r, _) in selected_rules:\n",
    "            scores[list(df.query(r).index)] += 1\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def score_top_rules(self, X):\n",
    "        \"\"\"Оценка, представляющая порядок между базовыми классификаторами (правилами).\n",
    "\n",
    "        Оценка высока, когда экземпляр обнаруживается правилом выполнения.\n",
    "        Если есть n правил, упорядоченных по возрастанию точности OOB,\n",
    "        оценка k означает, что k-е правило проголосовало положительно,\n",
    "        но не (k-1) первые правила.\n",
    "\n",
    "        Параметры\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Тренировочный набор данных\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        scores : array, shape (n_samples,)\n",
    "            Оценка входных данных.\n",
    "            Положительные баллы представляют выбросы, нулевые баллы - вставки(inliers).\n",
    "        \"\"\"\n",
    "        # Проверяем если был вызван метод fit\n",
    "        check_is_fitted(self, ['rules_', 'estimators_', 'estimators_samples_',\n",
    "                               'max_samples_'])\n",
    "\n",
    "        # Проверка входных данных\n",
    "        X = check_array(X)\n",
    "\n",
    "        if X.shape[1] != self.n_features_:\n",
    "            raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n",
    "                             \"the number of features at training time.\"\n",
    "                             \" Please reshape your data.\"\n",
    "                             % (X.shape[1], self.n_features_))\n",
    "\n",
    "        df = pd.DataFrame(X, columns=self.feature_names_)\n",
    "        selected_rules = self.rules_without_feature_names_\n",
    "\n",
    "        scores = np.zeros(X.shape[0])\n",
    "        for (k, r) in enumerate(list((selected_rules))):\n",
    "            scores[list(df.query(r[0]).index)] = np.maximum(\n",
    "                len(selected_rules) - k,\n",
    "                scores[list(df.query(r[0]).index)])\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def predict_top_rules(self, X, n_rules):\n",
    "        \"\"\"Прогноз, является ли конкретная выборка выбросом,\n",
    "         используя n_rules наиболее эффективных правил.\n",
    "\n",
    "        Параметры\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Входные данные. Внутри будут преобразованны в тип\n",
    "            ``dtype=np.float32``\n",
    "\n",
    "        n_rules : int\n",
    "            Количество правил, используемых для прогноза.\n",
    "            Если активировано одно из n_rules наиболее эффективных правил, прогноз равен 1.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        is_outlier : array, shape (n_samples,)\n",
    "            Для каждого наблюдения указывает, следует ли (1 или 0) рассматривать\n",
    "            его как выброс в соответствии с выбранными правилами.\n",
    "        \"\"\"\n",
    "\n",
    "        return np.array((self.score_top_rules(X) > len(self.rules_) - n_rules),\n",
    "                        dtype=int)\n",
    "\n",
    "    def _tree_to_rules(self, tree, feature_names):\n",
    "        \"\"\"\n",
    "        Возвращает список правил из дерева\n",
    "\n",
    "        Параметры\n",
    "        ----------\n",
    "            tree : дерево решений Classifier/Regressor\n",
    "            feature_names: список признаков\n",
    "\n",
    "        Возвращает\n",
    "        -------\n",
    "        rules : список правил.\n",
    "        \"\"\"\n",
    "        # XXX todo: check the case where tree is build on subset of features,\n",
    "        # ie max_features != None\n",
    "\n",
    "        tree_ = tree.tree_\n",
    "        feature_name = [\n",
    "            feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "            for i in tree_.feature\n",
    "        ]\n",
    "        rules = []\n",
    "\n",
    "        def recurse(node, base_name):\n",
    "            if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "                name = feature_name[node]\n",
    "                symbol = '<='\n",
    "                symbol2 = '>'\n",
    "                threshold = tree_.threshold[node]\n",
    "                text = base_name + [\"{} {} {}\".format(name, symbol, threshold)]\n",
    "                recurse(tree_.children_left[node], text)\n",
    "\n",
    "                text = base_name + [\"{} {} {}\".format(name, symbol2,\n",
    "                                                      threshold)]\n",
    "                recurse(tree_.children_right[node], text)\n",
    "            else:\n",
    "                rule = str.join(' and ', base_name)\n",
    "                rule = (rule if rule != ''\n",
    "                        else ' == '.join([feature_names[0]] * 2))\n",
    "                # правило выбора всех установлено \"c0==c0\"\n",
    "                rules.append(rule)\n",
    "\n",
    "        recurse(0, [])\n",
    "\n",
    "        return rules if len(rules) > 0 else 'True'\n",
    "\n",
    "    # функция вычисления производительности правила\n",
    "    def _eval_rule_perf(self, rule, X, y):\n",
    "        detected_index = list(X.query(rule).index)\n",
    "        if len(detected_index) <= 1:\n",
    "            return (0, 0)\n",
    "        y_detected = y[detected_index]\n",
    "        true_pos = y_detected[y_detected > 0].sum()\n",
    "        if true_pos == 0:\n",
    "            return (0, 0)\n",
    "        pos = y[y > 0].sum()\n",
    "        return y_detected.mean(), float(true_pos) / pos\n",
    "\n",
    "    # функция вычисления дедупликации правил\n",
    "    def deduplicate(self, rules):\n",
    "        return [max(rules_set, key=self.f1_score)\n",
    "                for rules_set in self._find_similar_rulesets(rules)]\n",
    "\n",
    "    def _find_similar_rulesets(self, rules):\n",
    "        \"\"\"Создавайте кластеры правил используя деревья решений на основе условий правил\n",
    "\n",
    "        Параметры\n",
    "        ----------\n",
    "        rules : List, List of rules\n",
    "                Правила, которые следует разделить на подмножества похожих правил\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        rules : List of list of rules\n",
    "                Разное множество правил. Каждое множество должно быть однородным\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        def split_with_best_feature(rules, depth, exceptions=[]):\n",
    "            \"\"\"\n",
    "            Метод поиска разделения правил с учетом наиболее репрезентативных признаков\n",
    "            \"\"\"\n",
    "            if depth == 0:\n",
    "                return rules\n",
    "\n",
    "            rulelist = [rule.split(' and ') for rule, score in rules]\n",
    "            terms = [t.split(' ')[0] for term in rulelist for t in term]\n",
    "            counter = Counter(terms)\n",
    "            # Удалить список исключений\n",
    "            for exception in exceptions:\n",
    "                del counter[exception]\n",
    "\n",
    "            if len(counter) == 0:\n",
    "                return rules\n",
    "\n",
    "            most_represented_term = counter.most_common()[0][0]\n",
    "            # Приступить к разделению\n",
    "            rules_splitted = [[], [], []]\n",
    "            for rule in rules:\n",
    "                if (most_represented_term + ' <=') in rule[0]:\n",
    "                    rules_splitted[0].append(rule)\n",
    "                elif (most_represented_term + ' >') in rule[0]:\n",
    "                    rules_splitted[1].append(rule)\n",
    "                else:\n",
    "                    rules_splitted[2].append(rule)\n",
    "            new_exceptions = exceptions + [most_represented_term]\n",
    "            # Выбрать лучшее term\n",
    "            return [split_with_best_feature(ruleset,\n",
    "                                            depth - 1,\n",
    "                                            exceptions=new_exceptions)\n",
    "                    for ruleset in rules_splitted]\n",
    "        # поиск в ширину по дереву\n",
    "        def breadth_first_search(rules, leaves=None):\n",
    "            if len(rules) == 0 or not isinstance(rules[0], list):\n",
    "                if len(rules) > 0:\n",
    "                    return leaves.append(rules)\n",
    "            else:\n",
    "                for rules_child in rules:\n",
    "                    breadth_first_search(rules_child, leaves=leaves)\n",
    "            return leaves\n",
    "\n",
    "        leaves = []\n",
    "        res = split_with_best_feature(rules, self.max_depth_duplication)\n",
    "        breadth_first_search(res, leaves=leaves)\n",
    "        return leaves\n",
    "\n",
    "    # функция расчета f1 метрики\n",
    "    def f1_score(self, x):\n",
    "        return 2 * x[1][0] * x[1][1] / \\\n",
    "               (x[1][0] + x[1][1]) if (x[1][0] + x[1][1]) > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Документация`: https://skope-rules.readthedocs.io/en/latest/index.html\n",
    "\n",
    "Skope-rules нацелены на изучение логических,\n",
    "интерпретируемых правил для «определения области действия» целевого класса,\n",
    "то есть обнаружения с высокой точностью экземпляров этого класса.\n",
    "SkopeRules можно использовать для описания классов с помощью логических правил.\n",
    "\n",
    "SkopeRules - позволяет получить логические правила при классификации, подходит для\n",
    "классификации несбалансированных классов, обнаружить аномалии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание классов с помощью логических правил"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal_length - длина наружной доли околоцветника\n",
      "sepal_width - ширина наружной доли околоцветника \n",
      "petal_length - длина внутренней доли околоцветника\n",
      "petal_width - ширина внутренней доли околоцветника\n",
      "****************************************************************************************************\n",
      "Правило: ирис щетинистый\n",
      "('petal_width <= 0.800000011920929', (1.0, 1.0, 20))\n",
      "('petal_length <= 2.449999988079071', (1.0, 1.0, 24))\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Правило: ирис разноцветный\n",
      "('petal_length <= 4.950000047683716 and petal_length > 2.449999988079071 and petal_width <= 1.75', (1.0, 1.0, 4))\n",
      "('sepal_length > 4.950000047683716 and petal_length <= 4.8500001430511475 and petal_width > 0.800000011920929', (0.8461538461538461, 0.9166666666666666, 1))\n",
      "('sepal_length <= 7.099999904632568 and petal_length > 2.449999988079071 and petal_width <= 1.75', (0.75, 1.0, 1))\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Правило: ирис виргинский\n",
      "('petal_length > 4.75 and petal_width > 1.75', (0.8819444444444444, 1.0, 2))\n",
      "('petal_width > 1.75', (0.9077777777777778, 0.863916083916084, 5))\n",
      "('petal_length > 5.049999952316284', (0.8869047619047619, 0.8333333333333333, 2))\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# загружаем набор данных Ирисов Фишера\n",
    "dataset = load_iris()\n",
    "# имена признаков\n",
    "feature_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "\n",
    "feature_names_ru = ['длина наружной доли околоцветника', 'ширина наружной доли околоцветника ',\n",
    "                 'длина внутренней доли околоцветника', 'ширина внутренней доли околоцветника']\n",
    "dct_feature_names_ru = dict(zip(feature_names, feature_names_ru))\n",
    "for k,v in dct_feature_names_ru.items():\n",
    "    print(f'{k} - {v}')\n",
    "print(100*'*')\n",
    "dct_ru_names_iris = {'setosa': 'ирис щетинистый', 'versicolor': 'ирис разноцветный', 'virginica': 'ирис виргинский'}\n",
    "clf = SkopeRules(max_depth_duplication=2,\n",
    "                 n_estimators=30,\n",
    "                 precision_min=0.3,\n",
    "                 recall_min=0.1,\n",
    "                 feature_names=feature_names)\n",
    "\n",
    "for idx, species in enumerate(dataset.target_names):\n",
    "    X, y = dataset.data, dataset.target\n",
    "    clf.fit(X, y == idx)\n",
    "    rules = clf.rules_[0:3]\n",
    "    print(\"Правило:\", dct_ru_names_iris[species])\n",
    "    for rule in rules:\n",
    "        print(rule)\n",
    "    print()\n",
    "    print(100 * '=')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Использование в качестве описания кластеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "пример: https://github.com/scikit-learn-contrib/skope-rules/blob/master/notebooks/demo_clustering.ipynb\n",
    "\n",
    "Данные `CompleteDataset.csv`: https://www.kaggle.com/thec03u5/fifa-18-demo-player-dataset/data. \n",
    "\n",
    "Датасет описывает футболистов и их характеристики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "data = pd.read_csv('CompleteDataset.csv')\n",
    "# Выберем игроков с общим атрибутом больше 85/100.\n",
    "data = data.query(\"Overall>=85\")\n",
    "\n",
    "column_to_keep = ['Name', 'Acceleration', 'Aggression', 'Agility', 'Balance', 'Ball control',\n",
    "       'Composure', 'Crossing', 'Curve', 'Dribbling', 'Finishing',\n",
    "       'Free kick accuracy', 'GK diving', 'GK handling', 'GK kicking',\n",
    "       'GK positioning', 'GK reflexes', 'Heading accuracy', 'Preferred Positions']\n",
    "# Сохраним только атрибуты производительности и имена.\n",
    "data = data[column_to_keep]\n",
    "\n",
    "# Заменим пробелы в именах столбцов\n",
    "data.columns = [x.replace(' ', '_') for x in data.columns]\n",
    "\n",
    "feature_names = data.drop(['Name', 'Preferred_Positions'], axis=1).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем 4 кластера\n",
    "clust = AgglomerativeClustering(n_clusters=4)\n",
    "data['cluster'] = clust.fit_predict(data.drop(['Name', 'Preferred_Positions'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      "[('Free_kick_accuracy > 56.0 and Heading_accuracy > 58.5 and Agility <= 81.5', (0.9354838709677419, 0.8529411764705882, 10))]\n",
      "Cluster 1:\n",
      "[('Aggression <= 76.5 and Agility > 81.5 and Balance > 66.5', (1.0, 0.7741935483870968, 8))]\n",
      "Cluster 2:\n",
      "[('Heading_accuracy > 82.5 and Curve <= 61.5', (1.0, 0.7857142857142857, 8))]\n",
      "Cluster 3:\n",
      "[('Curve <= 28.0', (1.0, 1.0, 4))]\n"
     ]
    }
   ],
   "source": [
    "# Проходим в цикле по каждому кластеру отдельно и выводим правила\n",
    "i_cluster = 0\n",
    "for i_cluster in range(4):\n",
    "    X_train = data.drop(['Name', 'Preferred_Positions', 'cluster'], axis=1)\n",
    "    y_train = (data['cluster']==i_cluster)*1\n",
    "    skope_rules_clf = SkopeRules(feature_names=feature_names, random_state=42, n_estimators=5,\n",
    "                                   recall_min=0.5, precision_min=0.5, max_depth_duplication=0,\n",
    "                                   max_samples=1., max_depth=3)\n",
    "    skope_rules_clf.fit(X_train, y_train)\n",
    "    print('Cluster '+str(i_cluster)+':')\n",
    "    #print(data.query('cluster=='+str(i_cluster))[['Name', 'Preferred_Positions']])\n",
    "    print(skope_rules_clf.rules_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В `кластере 0` мы находим игроков с хорошей игрой головой и точностью в штрафных, но не самых ловких игроков (<= 81/100). \n",
    "\n",
    "Это правило хорошо описывает кластер 0: он захватывает 85% кластера 1 с точностью 93% (7% игроков, описываемых правилом, не входят в кластер 0). Третий член показателя производительности (10) - это количество раз, когда это правило было извлечено из деревьев, построенных во время подбора правил skope.\n",
    "\n",
    "В `кластере 1` мы находим очень гибких игроков, которые не самые агрессивные, но уравновешенные. Это правило очень точное, но не учитывает 23% этого кластера.\n",
    "\n",
    "В `кластере 2` мы находим игроков, которые с точной игрой головой, но с меньшими навыками ведения дриблинга (кривая).\n",
    "\n",
    "В `кластере 3` мы находим игроков, которые очень плохо ведут мяч. Это правило идеально определяет кластер (100% точность, 100% отзыв). Это вратарская группа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 players from cluster 0:\n",
      "['M. Hamšík', 'Alex Sandro', 'Casemiro', 'K. Benzema', 'Z. Ibrahimović']\n",
      "\n",
      "5 players from cluster 1:\n",
      "['H. Mkhitaryan', 'David Silva', 'F. Ribéry', 'J. Rodríguez', 'P. Dybala']\n",
      "\n",
      "5 players from cluster 2:\n",
      "['Pepe', 'K. Glik', 'G. Chiellini', 'V. Kompany', 'Piqué']\n",
      "\n",
      "5 players from cluster 3:\n",
      "['M. ter Stegen', 'D. Subašić', 'M. Neuer', 'K. Navas', 'H. Lloris']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i_cluster in range(4):\n",
    "    print('5 players from cluster '+str(i_cluster)+':')\n",
    "    print(data.query(\"cluster==\"+str(i_cluster))['Name'].sample(5, random_state=42).tolist()) # Get 5 random players per cluster\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Короче говоря, `кластер 0` имеет тенденцию концентрировать нападающих и полузащитников, талантливых своей головой. `Кластер 1` имеет тенденцию группировать других полузащитников. `Кластер 2` сосредоточен на защитниках, а вратари собираются в `кластере 3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решение проблемы бинарной классификации на примере данных titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "пример: https://github.com/scikit-learn-contrib/skope-rules/blob/master/notebooks/demo_titanic.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading titanic.zip to /home/ilgrad/Desktop/development/jupyter/Gewissta_courses/notebooks/algorithms/skope_rules\n",
      "  0%|                                               | 0.00/34.1k [00:00<?, ?B/s]\n",
      "100%|██████████████████████████████████████| 34.1k/34.1k [00:00<00:00, 1.69MB/s]\n"
     ]
    }
   ],
   "source": [
    "# скачаем данные\n",
    "!kaggle competitions download -c titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  titanic.zip\n",
      "  inflating: data/gender_submission.csv  \n",
      "  inflating: data/test.csv           \n",
      "  inflating: data/train.csv          \n"
     ]
    }
   ],
   "source": [
    "# распакуем архив\n",
    "!unzip titanic.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are: Pclass Age SibSp Parch Fare isFemale Embarked_C Embarked_Q Embarked_S.\n",
      "Shape of training set is: (535, 9).\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/train.csv')\n",
    "# удалим строки без возраста\n",
    "data = data.query('Age == Age')\n",
    "\n",
    "# создадим dummy для переменой Sex\n",
    "data['isFemale'] = (data['Sex'] == 'female') * 1\n",
    "\n",
    "# Создадим dummies для переменной Embarked\n",
    "data = pd.concat(\n",
    "    [data,\n",
    "    pd.get_dummies(data.loc[:,'Embarked'], dummy_na=False, prefix='Embarked', prefix_sep='_')],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# удалим неиспользуемые колонки\n",
    "data = data.drop(['Name', 'Ticket', 'Cabin', 'PassengerId', 'Sex', 'Embarked'], axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(['Survived'], axis=1), data['Survived'], test_size=0.25, random_state=42)\n",
    "feature_names = X_train.columns\n",
    "\n",
    "print('Column names are: ' + ' '.join(feature_names.tolist())+'.')\n",
    "print('Shape of training set is: ' + str(X_train.shape) + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a gradient boosting classifier for benchmark\n",
    "gradient_boost_clf = GradientBoostingClassifier(random_state=42, n_estimators=30, max_depth = 5)\n",
    "gradient_boost_clf.fit(X_train, y_train)\n",
    "\n",
    "# Train a random forest classifier for benchmark\n",
    "random_forest_clf = RandomForestClassifier(random_state=42, n_estimators=30, max_depth = 5)\n",
    "random_forest_clf.fit(X_train, y_train)\n",
    "\n",
    "# Train a decision tree classifier for benchmark\n",
    "decision_tree_clf = DecisionTreeClassifier(random_state=42, max_depth = 5)\n",
    "decision_tree_clf.fit(X_train, y_train)\n",
    "\n",
    "# Train a skope-rules-boosting classifier\n",
    "skope_rules_clf = SkopeRules(feature_names=feature_names, random_state=42, n_estimators=30,\n",
    "                               recall_min=0.05, precision_min=0.9,\n",
    "                               max_samples=0.7,\n",
    "                               max_depth_duplication= 4, max_depth = 5)\n",
    "skope_rules_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Compute prediction scores\n",
    "gradient_boost_scoring = gradient_boost_clf.predict_proba(X_test)[:, 1]\n",
    "random_forest_scoring = random_forest_clf.predict_proba(X_test)[:, 1]\n",
    "decision_tree_scoring = decision_tree_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "skope_rules_scoring = skope_rules_clf.score_top_rules(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 правила были построены с помощью SkopeRules.\n",
      "\n",
      "4 наиболее эффективных \"правила выживания Титаника\" заключаются в следующем:\n",
      "\n",
      "Pclass <= 2.5 and Age <= 37.0 and Age > 2.5 and isFemale > 0.5\n",
      "-> Женщины в возрасте до 3 и 37, которые были в первом или втором классе.\n",
      "\n",
      "Pclass <= 2.5 and Age > 2.5 and Fare > 26.125 and isFemale > 0.5\n",
      "-> Женщины в возрасте более 3 лет в первом или втором классе, которые заплатили более 26€.\n",
      "\n",
      "Pclass <= 2.5 and Fare > 29.356249809265137 and isFemale > 0.5\n",
      "-> Женщины первого или второго класса, которые платили больше, чем 29€.\n",
      "\n",
      "Pclass <= 2.5 and Age > 38.5 and isFemale > 0.5\n",
      "-> Женщины старше 39 лет, в первом или втором классе.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Выведем число правил для выживания\n",
    "print(str(len(skope_rules_clf.rules_)) + ' правила были построены с помощью ' +\n",
    "      'SkopeRules.\\n')\n",
    "\n",
    "\n",
    "rules_explanations = [\n",
    "    'Женщины в возрасте до 3 и 37, которые были в первом или втором классе.',\n",
    "    'Женщины в возрасте более 3 лет в первом или втором классе, которые заплатили более 26€.',\n",
    "    'Женщины первого или второго класса, которые платили больше, чем 29€.',\n",
    "    'Женщины старше 39 лет, в первом или втором классе.'\n",
    "]\n",
    "print('4 наиболее эффективных \"правила выживания Титаника\" заключаются в следующем:\\n')\n",
    "for i_rule, rule in enumerate(skope_rules_clf.rules_[:4]):\n",
    "    print(rule[0])\n",
    "    print('-> '+rules_explanations[i_rule]+ '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность = 0.96 означает, что 96% людей, идентифицированных по этому правилу, являются выжившими.\n",
      "Полнота = 0.12 означает, что выжившие, идентифицированные правилом, составляют 12% от общего числа выживших.\n",
      "\n",
      "Правило 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_set</th>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.344037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_set</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.361111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           precision    recall\n",
       "train_set   0.974026  0.344037\n",
       "test_set    0.928571  0.361111"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правило 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_set</th>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.339450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_set</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           precision    recall\n",
       "train_set   0.986667  0.339450\n",
       "test_set    0.960000  0.333333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правило 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_set</th>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.311927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_set</th>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.263889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           precision    recall\n",
       "train_set   0.985507  0.311927\n",
       "test_set    0.950000  0.263889"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правило 4:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_set</th>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.151376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_set</th>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           precision    recall\n",
       "train_set   0.942857  0.151376\n",
       "test_set    0.923077  0.166667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_y_pred_from_query(X, rule):\n",
    "    score = np.zeros(X.shape[0])\n",
    "    X = X.reset_index(drop=True)\n",
    "    score[list(X.query(rule).index)] = 1\n",
    "    return(score)\n",
    "\n",
    "def compute_performances_from_y_pred(y_true, y_pred, index_name='default_index'):\n",
    "    df = pd.DataFrame(data=\n",
    "        {\n",
    "            'precision':[sum(y_true * y_pred)/sum(y_pred)],\n",
    "            'recall':[sum(y_true * y_pred)/sum(y_true)]\n",
    "        },\n",
    "        index=[index_name],\n",
    "        columns=['precision', 'recall']\n",
    "    )\n",
    "    return(df)\n",
    "\n",
    "def compute_train_test_query_performances(X_train, y_train, X_test, y_test, rule):\n",
    "    \n",
    "    y_train_pred = compute_y_pred_from_query(X_train, rule)\n",
    "    y_test_pred = compute_y_pred_from_query(X_test, rule)\n",
    "    \n",
    "    performances = None\n",
    "    performances = pd.concat([\n",
    "        performances,\n",
    "        compute_performances_from_y_pred(y_train, y_train_pred, 'train_set')],\n",
    "        axis=0)\n",
    "    performances = pd.concat([\n",
    "        performances,\n",
    "        compute_performances_from_y_pred(y_test, y_test_pred, 'test_set')],\n",
    "        axis=0)\n",
    "            \n",
    "    return(performances)\n",
    "\n",
    "\n",
    "print('Точность = 0.96 означает, что 96% людей, идентифицированных по этому правилу, являются выжившими.')\n",
    "print('Полнота = 0.12 означает, что выжившие, идентифицированные правилом, составляют 12% от общего числа выживших.\\n')\n",
    "\n",
    "for i in range(4):\n",
    "    print('Правило '+str(i+1)+':')\n",
    "    display(compute_train_test_query_performances(X_train, y_train,\n",
    "                                                  X_test, y_test,\n",
    "                                                  skope_rules_clf.rules_[i][0])\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_titanic_scores(y_true, scores_with_line=[], scores_with_points=[],\n",
    "                        labels_with_line=['Gradient Boosting', 'Random Forest', 'Decision Tree'],\n",
    "                        labels_with_points=['skope-rules']):\n",
    "    gradient = np.linspace(0, 1, 10)\n",
    "    color_list = [ cm.tab10(x) for x in gradient ]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5),\n",
    "                         sharex=True, sharey=True)\n",
    "    ax = axes[0]\n",
    "    n_line = 0\n",
    "    for i_score, score in enumerate(scores_with_line):\n",
    "        n_line = n_line + 1\n",
    "        fpr, tpr, _ = roc_curve(y_true, score)\n",
    "        ax.plot(fpr, tpr, linestyle='-.', c=color_list[i_score], lw=1, label=labels_with_line[i_score])\n",
    "    for i_score, score in enumerate(scores_with_points):\n",
    "        fpr, tpr, _ = roc_curve(y_true, score)\n",
    "        ax.scatter(fpr[:-1], tpr[:-1], c=color_list[n_line + i_score], s=10, label=labels_with_points[i_score])\n",
    "    ax.set_title(\"ROC\", fontsize=20)\n",
    "    ax.set_xlabel('Доля ложно положительных', fontsize=18)\n",
    "    ax.set_ylabel('Доля истинно положительных (Полнота)', fontsize=18)\n",
    "    ax.legend(loc='lower center', fontsize=8)\n",
    "\n",
    "    ax = axes[1]\n",
    "    n_line = 0\n",
    "    for i_score, score in enumerate(scores_with_line):\n",
    "        n_line = n_line + 1\n",
    "        precision, recall, _ = precision_recall_curve(y_true, score)\n",
    "        ax.step(recall, precision, linestyle='-.', c=color_list[i_score], lw=1, where='post', label=labels_with_line[i_score])\n",
    "    for i_score, score in enumerate(scores_with_points):\n",
    "        precision, recall, _ = precision_recall_curve(y_true, score)\n",
    "        ax.scatter(recall, precision, c=color_list[n_line + i_score], s=10, label=labels_with_points[i_score])\n",
    "    ax.set_title(\"Точность-Полнота\", fontsize=20)\n",
    "    ax.set_xlabel('Полнота (Доля истинно положительных)', fontsize=18)\n",
    "    ax.set_ylabel('Точность', fontsize=18)\n",
    "    ax.legend(loc='lower center', fontsize=8)\n",
    "    plt.show()\n",
    "    \n",
    "plot_titanic_scores(y_test,\n",
    "                    scores_with_line=[gradient_boost_scoring, random_forest_scoring, decision_tree_scoring],\n",
    "                    scores_with_points=[skope_rules_scoring]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На кривой `ROC` каждая красная точка соответствует ряду активированных правил (из skope-rules).\n",
    "Например, самая низкая точка - это оценка эффективности для 1 правила (лучшая). Вторая самая низкая точка - это график для 2 правила и т. д.\n",
    "\n",
    "На кривой Точность-Полнота(Precision-Recall) нанесены одни и те же точки, но с разными осями. Предупреждение: первая красная точка слева (отзыв 0%, точность 100%) соответствует правилу 0. Второй пункт слева - это первое правило и т. д.\n",
    "\n",
    "Из этого примера можно сделать некоторые выводы:\n",
    "\n",
    "* skope-rules работает лучше, чем дерево решений.\n",
    "* skope-rules имеют те же характеристики, что и усиление случайного леса / градиента (в этом примере)\n",
    "* Использование 4 правил приводит к отличной производительности (61% отзыв, 94% точность) (в этом примере)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Показатели достигнуты с 4 обнаруженные правила следующие:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_set</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          precision    recall\n",
       "test_set   0.928571  0.541667"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_rule_chosen = 4\n",
    "y_pred = skope_rules_clf.predict_top_rules(X_test, n_rule_chosen)\n",
    "\n",
    "print('Показатели достигнуты с '+str(n_rule_chosen)+' обнаруженные правила следующие:')\n",
    "compute_performances_from_y_pred(y_test, y_pred, 'test_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv_39",
   "language": "python",
   "name": "pyenv39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
